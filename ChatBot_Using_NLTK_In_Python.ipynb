{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "source": [
        "!pip install nltk"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvPosbS2uOCX",
        "outputId": "dffadbcd-15c3-445c-f871-f5dceb657efd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rkjrxh9guRlJ",
        "outputId": "ee22400f-693b-4d9a-e8ed-6a5706715b8e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import string\n",
        "import random"
      ],
      "metadata": {
        "id": "xSf4DYe6uVWb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "SYu_wpCzubTv"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_qa_pairs_from_file(file_path):\n",
        "    qa_pairs = []\n",
        "    with open(file_path, 'r', errors='ignore') as file:\n",
        "        for line in file:\n",
        "            if '|' in line:\n",
        "                question, answer = line.split('|', 1)\n",
        "                qa_pairs.append((question.strip(), answer.strip()))\n",
        "    return qa_pairs"
      ],
      "metadata": {
        "id": "LlaLhkqHufNg"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_file = '/content/data.txt'\n",
        "qa_pairs = read_qa_pairs_from_file(data_file)"
      ],
      "metadata": {
        "id": "9ZZ8l9Weuivr"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LemNormalize(text):\n",
        "    lemmer = nltk.stem.WordNetLemmatizer()\n",
        "    remove_punc_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "    return [lemmer.lemmatize(token.lower().translate(remove_punc_dict)) for token in nltk.word_tokenize(text)]"
      ],
      "metadata": {
        "id": "Kh2axMGAuuUN"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def response(user_response):\n",
        "    robo_response = ''\n",
        "    qa_pairs.append((' '.join(LemNormalize(user_response)), ''))  # Add user input to QA pairs\n",
        "\n",
        "    # Prepare TF-IDF vectors\n",
        "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
        "    tfidf = TfidfVec.fit_transform([pair[0] for pair in qa_pairs])\n",
        "\n",
        "    # Calculate similarity between user input and existing questions\n",
        "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "    idx = vals.argsort()[0][-2]  # Get index of most similar question\n",
        "\n",
        "    if vals[0][idx] > 0.0:  # If similarity score is above threshold\n",
        "        robo_response = qa_pairs[idx][1]\n",
        "    else:\n",
        "        robo_response = \"I am sorry. I don't understand that.\"\n",
        "\n",
        "    qa_pairs.pop()  # Remove user input from QA pairs\n",
        "    return robo_response\n",
        "\n",
        "# Main interaction loop\n",
        "print(\"Hello! I am the Learning Bot. Start typing your text after greeting to talk to me. To end the conversation, type 'bye'.\")\n",
        "\n",
        "while True:\n",
        "    user_response = input(\"You: \").lower()\n",
        "\n",
        "    if user_response == 'bye':\n",
        "        print('Bot: Goodbye!')\n",
        "        break\n",
        "\n",
        "    print('Bot:', response(user_response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20ab2d17-e285-49bc-9a13-799af31d44a5",
        "id": "Hn9LYSntuz39"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I am the Learning Bot. Start typing your text after greeting to talk to me. To end the conversation, type 'bye'.\n",
            "You: hey\n",
            "Bot: I am sorry. I don't understand that.\n",
            "You: how you are doing?\n",
            "Bot: I'm doing well, thank you!\n",
            "You: what is your name?\n",
            "Bot: I am sorry. I don't understand that.\n",
            "You: Can you help me with something?\n",
            "Bot: Sure, I'll do my best to assist you.\n",
            "You: Do you like talking to people?\n",
            "Bot: I'm here to chat with you!\n",
            "You: What are your favorite topics to chat about?\n",
            "Bot: I enjoy discussing technology and science.\n",
            "You: bye\n",
            "Bot: Goodbye!\n"
          ]
        }
      ]
    }
  ]
}